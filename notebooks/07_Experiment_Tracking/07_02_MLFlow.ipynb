{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility and deployment. It currently offers three components:\n",
    "    \n",
    "- *MLflow Tracking*: Record and query experiments: code, data, config, and results.\n",
    "- *MLflow Projects*: Packaging format for reproducible runs on any platform.\n",
    "- *MLflow Models*: General format for sending models to diverse deployment tools.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Tracking\n",
    "The MLflow Tracking component is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results. MLflow Tracking lets you log and query experiments using Python, REST, R API, and Java API APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts\n",
    "MLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code. Each run records the following information:\n",
    "\n",
    "#### Code Version\n",
    "Git commit hash used for the run, if it was run from an `MLflow Project`.\n",
    "\n",
    "#### Start & End Time\n",
    "Start and end time of the run\n",
    "\n",
    "#### Source\n",
    "Name of the file to launch the run, or the project name and entry point for the run if run from an `MLflow Project`.\n",
    "\n",
    "#### Parameters\n",
    "Key-value input parameters of your choice. Both keys and values are strings.\n",
    "\n",
    "#### Metrics\n",
    "Key-value metrics, where the value is numeric. Each metric can be updated throughout the course of the run (for example, to track how your model’s loss function is converging), and MLflow records and lets you visualize the metric’s full history.\n",
    "\n",
    "#### Artifacts\n",
    "Output files in any format. For example, you can record images (for example, PNGs), models (for example, a pickled scikit-learn model), and data files (for example, a Parquet file) as artifacts.\n",
    "You can record runs using MLflow Python, R, Java, and REST APIs from anywhere you run your code. For example, you can record them in a standalone program, on a remote cloud machine, or in an interactive notebook. If you record runs in an MLflow Project, MLflow remembers the project URI and source version.\n",
    "\n",
    "\n",
    "You can optionally organize runs into experiments, which group together runs for a specific task. You can create an experiment using the mlflow experiments CLI, with `mlflow.create_experiment()`, or using the corresponding REST parameters. The MLflow API and UI let you create and search for experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MLflow SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install mlflow==1.3.0 keras boto3 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MLFlow Tracking Server\n",
    "\n",
    "Open mlflow/mlflow.yaml and update `<YOUR_S3_BUCKET_NAME>` to an existing bucket name and make sure you have `aws-secret` in kubeflow namespace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deploy Mlflow tracking server\n",
    "# Since you are in `anonymous-kubeflow-org` namespace, you may not have permission to create components in kubeflow namespace.\n",
    "# Instead, please copy file to your local envrionment and this command.\n",
    "\n",
    "!kubectl apply -f mlflow/mlflow.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "MLflow Tracking is an API and UI for logging parameters, code versions, metrics and output files when running your machine learning code to later visualize them. With a few simple lines of code, you can track parameters, metrics, and artifacts:\n",
    "\n",
    "\n",
    "```py\n",
    "import mlflow\n",
    "\n",
    "# Log parameters (key-value pairs)\n",
    "mlflow.log_param(\"num_dimensions\", 8)\n",
    "mlflow.log_param(\"regularization\", 0.1)\n",
    "\n",
    "# Log a metric; metrics can be updated throughout the run\n",
    "mlflow.log_metric(\"accuracy\", 0.1)\n",
    "...\n",
    "mlflow.log_metric(\"accuracy\", 0.45)\n",
    "\n",
    "# Log artifacts (output files)\n",
    "mlflow.log_artifact(\"roc.png\")\n",
    "mlflow.log_artifact(\"model.pkl\")\n",
    "\n",
    "```\n",
    "\n",
    "You can use MLflow Tracking in any environment (for example, a standalone script or a notebook) to log results to local files or to a server, then compare multiple runs. Using the web UI, you can view and compare the output of multiple runs. Teams can also use the tools to compare results from different users:\n",
    "\n",
    "![mlflow-web-ui](mlflow/mlflow-web-ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "\n",
    "# Reduce spam logs from s3 client\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "\n",
    "def preprocessing():\n",
    "  fashion_mnist = keras.datasets.fashion_mnist\n",
    "  (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "  # scale the values to 0.0 to 1.0\n",
    "  train_images = train_images / 255.0\n",
    "  test_images = test_images / 255.0\n",
    "\n",
    "  # reshape for feeding into the model\n",
    "  train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "  test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "  print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
    "  print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))\n",
    "\n",
    "  return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def train(train_images, train_labels, epochs, model_summary_path):\n",
    "  if model_summary_path:\n",
    "    logdir=model_summary_path # + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3,\n",
    "                        strides=2, activation='relu', name='Conv1'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "  ])\n",
    "  model.summary()\n",
    "\n",
    "  model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "  if model_summary_path:\n",
    "    model.fit(train_images, train_labels, epochs=epochs, batch_size=64, callbacks=[tensorboard_callback])\n",
    "  else:\n",
    "    model.fit(train_images, train_labels, epochs=epochs, batch_size=64)\n",
    "\n",
    "  mlflow.log_param('batch_size', 64)\n",
    "\n",
    "  return model\n",
    "\n",
    "def eval(model, test_images, test_labels):\n",
    "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "  print('\\nTest accuracy: {}, test loss {}'.format(test_acc, test_loss))\n",
    "  mlflow.log_metric(\"accuracy\", test_acc)\n",
    "  mlflow.log_metric(\"loss\", test_loss)\n",
    "\n",
    "def export_model(model, model_export_path):\n",
    "  version = 1\n",
    "  export_path = os.path.join(model_export_path, str(version))\n",
    "\n",
    "  tf.saved_model.simple_save(\n",
    "    keras.backend.get_session(),\n",
    "    export_path,\n",
    "    inputs={'input_image': model.input},\n",
    "    outputs={t.name:t for t in model.outputs})\n",
    "\n",
    "  print('\\nSaved model: {}'.format(export_path))\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "  parser = argparse.ArgumentParser(description='Fashion MNIST Tensorflow Example')\n",
    "  parser.add_argument('--model_export_path', type=str, help='Model export path')\n",
    "  parser.add_argument('--model_summary_path', type=str,  help='Model summry files for Tensorboard visualization')\n",
    "  parser.add_argument('--epochs', type=int, default=5, help='Training epochs')\n",
    "  args = parser.parse_args(args=['--epochs=10'])\n",
    "\n",
    "  # File Based Tracking URI. Use NFS in this case\n",
    "  # users_home = '/tmp/shjiaxin'\n",
    "  # experiment_base_path = '%s/experiments' % users_home\n",
    "  # tracking_uri='file://%s' % experiment_base_path\n",
    "  \n",
    "  # Remote Tracking Server URI. Use kubernetes Service.\n",
    "  # Make sure you have installed MLflow\n",
    "  tracking_uri = \"http://mlflow-tracking-server.kubeflow.svc.cluster.local:5000\"\n",
    "  mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "  experiment_name = 'mlflow'\n",
    "  mlflow.set_experiment(experiment_name)\n",
    "\n",
    "  with mlflow.start_run() as run:\n",
    "    start_time = time.time()\n",
    "    train_images, train_labels, test_images, test_labels = preprocessing()\n",
    "    model = train(train_images, train_labels, args.epochs, args.model_summary_path)\n",
    "    eval(model, test_images, test_labels)\n",
    "\n",
    "    mlflow.log_param('epochs', args.epochs)\n",
    "\n",
    "    if args.model_export_path:\n",
    "      export_model(model, args.model_export_path)\n",
    "\n",
    "    # Use MLFlow fashion to persist model\n",
    "    mlflow.keras.log_model(model, 'model_keras')\n",
    "\n",
    "    # Measure running time\n",
    "    duration_in_seconds = time.time() - start_time\n",
    "    print(\"This model took\", duration_in_seconds, \"seconds to train and test.\")\n",
    "    mlflow.log_metric(\"time_duration\", duration_in_seconds)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance\n",
    "\n",
    "In your terminal, run `kubectl port-forward svc/mlflow-tracking-server -n kubeflow 5000:5000`. Then you can visit `localhost:5000` in your browser."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
