{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Monitoring Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we utilize iris dataset, trained with `sklearn` and `tensorflow` models, upload outputs to S3 bucket. And then kubeflow artifact can read from S3 bucket and show us the monitoring results including `Markdown`, `Confusion Matrix`, `ROC Curve` and `Tensorboard`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequiste\n",
    "1. Create a `aws-secret` with at least `S3ReadOnlyAccess` policy in `kubeflow` namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "  apiVersion: v1\n",
    "  kind: Secret\n",
    "  metadata:\n",
    "    name: aws-secret\n",
    "    namespace: kubeflow\n",
    "  type: Opaque\n",
    "  data:\n",
    "    AWS_ACCESS_KEY_ID: YOUR_BASE64_ACCESS_KEY\n",
    "    AWS_SECRET_ACCESS_KEY: YOUR_BASE64_SECRET_ACCESS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: To get base64 string, run `echo -n $AWS_ACCESS_KEY_ID | base64`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a configmap to store template spec of viewer tensorboard pod. Replace `<your_region>` with your S3 region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "  apiVersion: v1\n",
    "  kind: ConfigMap\n",
    "  metadata:\n",
    "    name: ml-pipeline-ui-viewer-template\n",
    "  data:\n",
    "    viewer-tensorboard-template.json: |\n",
    "      {\n",
    "          \"spec\": {\n",
    "              \"containers\": [\n",
    "                  {\n",
    "                      \"env\": [\n",
    "                          {\n",
    "                              \"name\": \"AWS_ACCESS_KEY_ID\",\n",
    "                              \"valueFrom\": {\n",
    "                                  \"secretKeyRef\": {\n",
    "                                      \"name\": \"aws-secret\",\n",
    "                                      \"key\": \"AWS_ACCESS_KEY_ID\"\n",
    "                                  }\n",
    "                              }\n",
    "                          },\n",
    "                          {\n",
    "                              \"name\": \"AWS_SECRET_ACCESS_KEY\",\n",
    "                              \"valueFrom\": {\n",
    "                                  \"secretKeyRef\": {\n",
    "                                      \"name\": \"aws-secret\",\n",
    "                                      \"key\": \"AWS_SECRET_ACCESS_KEY\"\n",
    "                                  }\n",
    "                              }\n",
    "                          },\n",
    "                          {\n",
    "                              \"name\": \"AWS_REGION\",\n",
    "                              \"value\": \"<your_region>\"\n",
    "                          }\n",
    "                      ]\n",
    "                  }\n",
    "              ]\n",
    "          }\n",
    "      }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Update deployment `ml-pipeline-ui` to use this sepc by running `kubectl edit deployment ml-pipeline-ui -n kubeflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "  apiVersion: extensions/v1beta1\n",
    "  kind: Deployment\n",
    "  metadata:\n",
    "    name: ml-pipeline-ui\n",
    "    namespace: kubeflow\n",
    "    ...\n",
    "  spec:\n",
    "    template:\n",
    "      spec:\n",
    "        containers:\n",
    "        - env:\n",
    "          - name: VIEWER_TENSORBOARD_POD_TEMPLATE_SPEC_PATH\n",
    "            value: /etc/config/viewer-tensorboard-template.json\n",
    "          ....\n",
    "          volumeMounts:\n",
    "          - mountPath: /etc/config\n",
    "            name: config-volume\n",
    "        .....\n",
    "        volumes:\n",
    "        - configMap:\n",
    "            defaultMode: 420\n",
    "            name: ml-pipeline-ui-viewer-template\n",
    "          name: config-volume\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create an S3 bucket to store pipeline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "HASH = ''.join([random.choice(string.ascii_lowercase) for n in range(16)] + [random.choice(string.digits) for n in range(16)])\n",
    "AWS_REGION = 'us-west-2'\n",
    "S3_BUCKET = '{}-kubeflow-pipeline-data'.format(HASH)\n",
    "!aws s3 mb s3://$S3_BUCKET --region $AWS_REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run the following command to load Kubeflow Pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from kfp.aws import use_aws_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load reusable components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_op = components.load_component_from_file('./src/09_01_Iris_Pipeline_Monitoring/component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='IRIS Classification pipeline',\n",
    "    description='IRIS Classification using LR in SKLEARN'\n",
    ")\n",
    "def iris_pipeline(s3_bucket=S3_BUCKET,\n",
    "                 aws_region=AWS_REGION):\n",
    "    \n",
    "    iris_task = iris_op(\n",
    "        s3_bucket=s3_bucket,\n",
    "        aws_region=aws_region,\n",
    "    ).apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compile and deploy your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(iris_pipeline, 'iris-classification-pipeline.zip')\n",
    "client = kfp.Client()\n",
    "aws_experiment = client.create_experiment(name='aws')\n",
    "my_run = client.run_pipeline(aws_experiment.id, 'iris-classification-pipeline', \n",
    "  'iris-classification-pipeline.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: After you saw the artifact with Tensorboard, and create a tensorboard 1.15.0, please wait 3-5 minutes for tensorboard to load data from S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard-artifact](./images/tbartifact.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete S3 bucket that was created for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 rb s3://$S3_BUCKET --force"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}